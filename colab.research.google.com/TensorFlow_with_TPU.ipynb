{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, TPU in Colab",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/natemurthy/misc/blob/master/colab.research.google.com/TensorFlow_with_GPU.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_pQCOmISAQBu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing out the TPU connection\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook.\n",
        "\n",
        "Navigate to Edit→Notebook Settings, and select TPU from the Hardware Accelerator drop-down (you can also access Notebook Settings via the command palette: cmd/ctrl-shift-P).\n",
        "\n",
        "Next, we'll check that we can connect to the TPU."
      ]
    },
    {
      "metadata": {
        "id": "PUINPtMG_w9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3a97f3e6-edbf-40c1-8ea7-6f68f01d9887"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print ('TPU address is', tpu_address)\n",
        "\n",
        "with tf.Session(tpu_address) as session:\n",
        "  devices = session.list_devices()\n",
        "  \n",
        "print ('TPU devices:')\n",
        "devices\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.22.86.138:8470\n",
            "TPU devices:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5367837999772260330),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10100309180633096616),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 16957089878897873948),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 15576818800597952368),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6563325799648670620),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 280552207182685731),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11447240344446465732),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13831751451533610930),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12942592464113598861),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3691822185360145325),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4567373785046838763),\n",
              " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 17045378757071738747)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Jkh7cEWRAEA-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the cell above reports an error, make sure that you have enabled TPU support in the notebook settings. (Edit menu → Notebook settings)\n",
        "\n",
        "Now, let's try a simple computation."
      ]
    },
    {
      "metadata": {
        "id": "0iqSZvc6AX1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f697b396-befa-47b1-b5f5-0fac4eeb84a3"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def add_op(x, y):\n",
        "  return x + y\n",
        "  \n",
        "x = tf.placeholder(tf.float32, [10,])\n",
        "y = tf.placeholder(tf.float32, [10,])\n",
        "tpu_ops = tf.contrib.tpu.rewrite(add_op, [x, y])\n",
        "  \n",
        "session = tf.Session(tpu_address)\n",
        "try:\n",
        "  print('Initializing...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "  print('Running ops')\n",
        "  print(session.run(tpu_ops, {x: np.arange(10), y: np.arange(10)}))\n",
        "finally:\n",
        "  # For now, TPU sessions must be shutdown separately from\n",
        "  # closing the session.\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing...\n",
            "Running ops\n",
            "[array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nhXwaCNWBK2n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TPU FLOPs\n",
        "\n",
        "Finally, we'll try a small test of floating point computations (floating point operations per seconds. (The units are FLOPS: floating point operations per second.)"
      ]
    },
    {
      "metadata": {
        "id": "llcFb_P_BNPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "227bf7c7-c818-41c3-c9f7-f73dcc818d89"
      },
      "cell_type": "code",
      "source": [
        "N = 4096\n",
        "COUNT = 100\n",
        "import time\n",
        "\n",
        "def flops():\n",
        "  x = tf.random_uniform([N, N])\n",
        "  y = tf.random_uniform([N, N])\n",
        "  def _matmul(x, y):\n",
        "    return tf.tensordot(x, y, axes=[[1], [0]]), y\n",
        "\n",
        "  return tf.reduce_sum(\n",
        "    tf.contrib.tpu.repeat(COUNT, _matmul, [x, y])\n",
        "  )\n",
        "  \n",
        "tpu_ops = tf.contrib.tpu.batch_parallel(flops, [], num_shards=8)\n",
        "  \n",
        "session = tf.Session(tpu_address)\n",
        "try:\n",
        "  print('Warming up...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "  session.run(tpu_ops)\n",
        "  print('Profiling')\n",
        "  start = time.time()\n",
        "  session.run(tpu_ops)\n",
        "  end = time.time()\n",
        "  elapsed = end - start\n",
        "  print(elapsed, 'TFlops: {:.2f}'.format(1e-12 * 8 * COUNT * 2*N*N*N / elapsed))\n",
        "finally:\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warming up...\n",
            "Profiling\n",
            "0.665576696395874 TFlops: 165.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a_rjVo-RAoYd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Next steps\n",
        "\n",
        "A more involved example is [Shakespeare in 5 minutes with Cloud TPUs and Keras](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb).\n",
        "\n",
        "We'll be sharing more examples of TPU use in Colab over time, so be sure to check back for additional example links, or [follow us on Twitter @GoogleColab](https://twitter.com/googlecolab).\n",
        "\n",
        "Meanwhile, you can check out the [TPUEstimator documentation on TensorFlow.org](https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator). TPUEstimator is an easy way to update models to take advantage of TPU acceleration."
      ]
    },
    {
      "metadata": {
        "id": "ZocOw-1OQJWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "85881d36-a5e8-41b0-fa76-79d8b3838d94"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "B = 100\n",
        "H = 100\n",
        "W = 100\n",
        "C = 3\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    with tf.Session() as sess:\n",
        "      random_image_cpu = tf.random_normal((B, H, W, C))\n",
        "      net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "      net_cpu = tf.reduce_sum(net_cpu)\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      sess.run(net_cpu)\n",
        "      sess.close()\n",
        "  \n",
        "def tpu():\n",
        "  with tf.Session('grpc://' + os.environ['COLAB_TPU_ADDR']) as sess:\n",
        "    random_image_tpu = tf.random_normal((B, H, W, C))\n",
        "    net_tpu = tf.layers.conv2d(random_image_tpu, 32, 7)\n",
        "    net_tpu = tf.reduce_sum(net_tpu)\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(net_tpu)\n",
        "    sess.close()\n",
        "\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random {}x{}x{}x{} images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.'.format(B,H,W,C))\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('TPU (s):')\n",
        "tpu_time = timeit.timeit('tpu()', number=10, setup=\"from __main__ import tpu\")\n",
        "print(tpu_time)\n",
        "print('TPU speedup over CPU: {}x'.format(int(cpu_time/tpu_time)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "10.55410370300001\n",
            "TPU (s):\n",
            "1.433097946000089\n",
            "TPU speedup over CPU: 7x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9nm_MaU-aLQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f2d91b8-3716-4d2e-a2a8-ac33cd5ee8fa"
      },
      "cell_type": "code",
      "source": [
        "def bench_tpu():\n",
        "  X = tf.random_normal([2000000, 10000], mean=-1, stddev=4)\n",
        "  Y = tf.random_normal([10000, 1], mean=-1, stddev=4)\n",
        "\n",
        "  with tf.Session('grpc://' + os.environ['COLAB_TPU_ADDR']) as sess:\n",
        "    sess.run(tf.matmul(X,Y))\n",
        "    sess.close()\n",
        "    \n",
        "print('TPU (s):')\n",
        "tpu_time = timeit.timeit('bench_tpu()', number=1, setup=\"from __main__ import bench_tpu\")\n",
        "print(tpu_time)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU (s):\n",
            "24.28661741699989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1IKlZTHPdL00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
