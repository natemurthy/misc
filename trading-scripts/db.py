import datetime as dt
import os
import psycopg as pg

from dataclasses import dataclass
from psycopg import sql
from psycopg_pool import ConnectionPool
from typing import Any, Literal, TypeAlias, TypeVar
from urllib import parse


# ---------------------------------------------------------------------------------------------------------------------
# NOTE: table struct data classes
# ---------------------------------------------------------------------------------------------------------------------

T = TypeVar('T')

SourceLiteral: TypeAlias = Literal["tipranks", "yfinance", "ycharts"]

@dataclass
class TableRowStruct:
    """Base class from which all table dataclass types inherit"""
    id: int | None  # generated by database, so this is None when writing to table
    created_at: dt.datetime | None # generated by database, so this is None when writing to table
    source: SourceLiteral
    symbol: str
    trading_day: dt.date
    last_closing_price: float


# ---------------------------------------------------------------------------------------------------------------------
# NOTE: Postgres connection config and client
# ---------------------------------------------------------------------------------------------------------------------

@dataclass
class PostgresConnectionConfig:
    host: str
    db_name: str
    username: str
    password: str
    port: int = 5432
    additional_connection_params: dict[str, Any] | None = None
    pool_params: dict[str, Any] | None = None  # if not passed, will not create a pool

    def get_unsafe_cxn_uri(self) -> str:
        encoded_password = parse.quote(self.password)
        uri = f"postgresql://{self.username}:{encoded_password}@{self.host}:{self.port}/{self.db_name}"
        if self.additional_connection_params is not None:
            uri += "?"
            for k, v in self.additional_connection_params.items():
                uri += f"{k}={v}&"
            uri = uri[:-1]  # removes trailing ampersand
        return uri


class PostgresClient:
    def __init__(self, config: PostgresConnectionConfig):
        self.config = config
        self._connection: pg.Connection

    def connect(self) -> pg.Connection | ConnectionPool:
        if not hasattr(self, '_connection'):
            if self.config.pool_params is not None:
                params = dict(
                    host=self.config.host,
                    dbname=self.config.db_name,
                    user=self.config.username,
                    password=self.config.password,
                    port=self.config.port,
                )
                # TODO add support for ConnectionPool, no currently in use
                self._connection = ConnectionPool(**self.config.pool_params, **params)
            else:
                self._connection = pg.connect(self.config.get_unsafe_cxn_uri())
                print("debug_db_client:", f"connected to {self.config.host}:{self.config.port}/{self.config.db_name}")
        return self._connection

    @staticmethod
    def _get_insertable_columns(row: TableRowStruct):
        """The "id", and "created_at" column values are generated by the DB at insertion time, so filter these from the
        set of columns available on any table row struct written
        """
        return [k for k in row.__dict__.keys() if k not in ["id", "created_at"]]

    def insert(
        self, schema_name: str, table_name: str, rows: list[T], id_column: str = "id"
    ) -> list[int]:
        """Insert rows into a specific database table

        Args:
            schema_name: container holding the table (likely going to be the 'analytics' schema)
            table_name: name of the table into which this client will write
            rows: rows to write into table typed to the schema
            id_column: name of the SQL identifier column to indicate written rows

        Returns:
            List of table row IDs written (assumed these are serial integers for now, but may be typeids)
        """
        # assumes the first row record appears like all the others
        insert_columns = self._get_insertable_columns(rows[0]) 
        insert_values = [[item.__dict__[col] for col in insert_columns] for item in rows]
        query = sql.SQL("""
                        INSERT INTO {schema_name}.{table_name}
                        ({columns}) VALUES ({values})
                        RETURNING {id_column}
                        """).format(
            schema_name=sql.Identifier(schema_name),
            table_name=sql.Identifier(table_name),
            columns=sql.SQL(",").join(list(map(sql.Identifier, insert_columns))),
            id_column=sql.Identifier(id_column),
            values=sql.SQL(" , ").join(sql.Placeholder() * len(insert_columns)),
        )
        with self._connection.cursor() as cur:
            cur.executemany(query, insert_values, returning=True)
            # in psycopg3 to return all returned ids we should loop through the cursor.
            ids = [cur.fetchone()[0]]
            while cur.nextset():
                ids.append(cur.fetchone()[0])
            self._connection.commit()
        return ids


def market_data_db_client():
    cfg = PostgresConnectionConfig(
        host=os.getenv("POSTGRES_HOST", "127.0.0.1"),
        db_name=os.getenv("POSTGRES_DBNAME", "market-data"),
        username=os.getenv("POSTGRES_USERNAME", "nathan"),
        password=os.getenv("POSTGRES_PASSWORD", "none"),
    )
    c = PostgresClient(cfg)
    return c
